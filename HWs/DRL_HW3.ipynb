{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ofEJa44_c8i"
      },
      "source": [
        "# HW3 - Model Based RL - Neural Dynamics Modeling, CEM, PETS\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2IwS_KnpqJL"
      },
      "source": [
        "#### Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPVkUrW6pUt_"
      },
      "source": [
        "**Model free vs model based**\n",
        "\n",
        "HW1 and HW2 explored **model free RL**. In that setting, we don't learn a dynamics model or plan using a dynamics model - hence model free. Theoretically, model free MDP exploration takes place directly in the real world - in practice this only works for **perfect simulators** where the training environment exactly matches the testing environment, like video games or board games. These approaches **learn policies** that map all states to optimal actions.\n",
        "\n",
        "This assignment explores **model based RL**. In this setting we **learn models** of the approximate transition dynamics from data and **plan actions with those models** - hence model based. This is required for robotics, autonomous driving, or any hardware system that is impossible to simulate perfectly.\n",
        "\n",
        "Note, there is also a broad gray area between model based and model free rl. You can approximate dynamics and then learn a policy, you can plan trajectories in a perfect simulator, etc. This distinction between the algorithm classes is more historical than deeply significant.\n",
        "\n",
        "**HW3**\n",
        "\n",
        "This assignment builds to an important recent work in model based RL - [PETS](https://arxiv.org/abs/1805.12114): probabilistic ensembles with trajectory sampling (2018). It progresses from predecessor techniques: deterministic neural dynamics modeling (\\~1990), Cross Entropy Method (\\~1999), and stochastic neural dynamics modeling (\\~1994).\n",
        "\n",
        "For this assignment, we pretend our [inverted pendulum](https://gymnasium.farama.org/environments/mujoco/inverted_pendulum/) environment is an expensive hardware system we have previously collected data from. From that data we will train models, and with those models we will plan actions.\n",
        "\n",
        "Note, variations of these algorithms exist. Please use the math contained in this notebook for the coding sections."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PHhuXXvnxb8"
      },
      "source": [
        "# 0. Warm Up Questions [30 pts total; 2 pt each]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaT41gO4n0zq"
      },
      "source": [
        "1.    What're the differences between an optimal policy and an optimal trajectory?<br>\n",
        "\n",
        "> An optimal policy $\\pi$ knows how to create an optimal trajectory $\\tau$, given different self/environment states. \n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "\n",
        "2.    In model free RL we search over all possible policy parameters $\\theta$ for optimal parameters $\\theta^*$ which result in the highest sum of rewards:\n",
        "$$\n",
        "\\theta^* = \\arg \\max_\\theta \\displaystyle\\sum_{t=1}^{T} r(s_t, a_t)\n",
        "$$\n",
        "In basic language, what is the meaning of this constrained optimization below, which is used to plan trajectories in model based RL? [hint: the deterministic case](https://www.youtube.com/watch?v=4SL0DnxC1GM&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=40)\n",
        "$$\n",
        "a_1^*, ..., a^*_T = \\arg \\max_{a_1, ..., a_T} \\displaystyle\\sum_{t=1}^T r(s_t, a_t)\\\\\n",
        "\\text{  subject to:  } s_{t+1} = s_t + f_\\theta(s_t, a_t)\n",
        "$$ <br>\n",
        "\n",
        "> The optimal trajectory ($a_1^*, ..., a^*_T$) is one that produces the maximum possible rewards ($r(s_t, a_t)$) given a situation whose state evolution (transition dynamics) is governed by the function $f_\\theta(s_t, a_t)$.\n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "\n",
        "2.    Why is it helpful to replan at every time step in a Model Predictive Control settings? [hint: What if we make a mistake](https://www.youtube.com/watch?v=LkTmiylbHYk&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=45)<br>\n",
        "\n",
        "> It allows the system to reduce the effects of error accumulation due to uncertainty in sensing and dynamics prediction — essentially turning it into a closed-loop feedback system. \n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "3.    What're the 3 basic steps of model based RL? [hint: mbrl v 0.5](https://www.youtube.com/watch?v=LkTmiylbHYk&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=46)<br>\n",
        "\n",
        "> 1. Obtain the dynamics model. 2. Interact with the environment. 3. Update the parameter weights.\n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "4.    Write a valid equation for mean squared error loss for a neural approximation to deterministic transition dynamics. Define any variables you use.<br>\n",
        "\n",
        "> $\\text{loss}_t = (s_{t+1} - \\hat{s_{t+1}})^2$, where $\\hat{s_{t+1}}$ is the predicted environment state at next step, and $s_{t+1}$ is the actual environment state.\n",
        "\n",
        "5.    What're the two steps in the \"guess & check\" method of stochastic optimization? Define any variables you use. [hint](https://www.youtube.com/watch?v=pd9mKcH4kkk&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=41)<br>\n",
        "\n",
        "6.    In general machine learning, what is an evolutionary algorithm?<br>\n",
        "\n",
        "> An algorithm that utilizes the generation of a set of parameter candidates via random sampling and \"natural selection\" as the update rule. \n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "7.    How does the cross entropy method improve on \"guess & check\"? What're the four steps of the cross entropy method? [hint](https://www.youtube.com/watch?v=pd9mKcH4kkk&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=41)<br>\n",
        "\n",
        "> \n",
        "\n",
        "8.    In guess and check or CEM, you have an environment with 5 continuous states and 3 continuous actions and you want to randomly sample 1000 trajectories, each 15 timesteps long. What size must your mean and standard deviation tensors be to allow this sampling?<br>\n",
        "\n",
        "> (5 + 3) * 15 * 1000 = shape (8, 15, 1000), size 120,000. \n",
        "\n",
        "> Wait, this is the data tensor size; since the mean/std are probably *reduced* over trajectories and timesteps, it's probably just 8?\n",
        "\n",
        "> `TODO`: what about standard deviation?\n",
        "\n",
        "9.    Alea is latin for dice. What is aleatoric uncertainty? <br>\n",
        "\n",
        "> Uncertainty due to the inherent combinatorial complexity of the environmental state. \n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "10.    What type of loss should you use to fit the parameters of a guassian to a set of random samples from a guassian? and why not just use MSE? [hint](https://pytorch.org/docs/stable/generated/torch.nn.GaussianNLLLoss.html)<br>\n",
        "\n",
        "> \n",
        "\n",
        "11.    Episteme is greek for knowledge. What is epistemic uncertainty? <br>\n",
        "\n",
        "> \n",
        "\n",
        "12.    In general machine learning, what is an ensemble?<br>\n",
        "\n",
        "> A class of techniques that involve generation of a set of (intermediary) output value candidates and holistically combine them to obtain a better accuracy (vs. without ensembling). \n",
        "\n",
        "> `TODO`: check\n",
        "\n",
        "13.    Why is sequential dynamics modeling harder than non sequential supervised learning?<br>\n",
        "\n",
        "> Because there is an added variable of time and state history/memory. \n",
        "\n",
        "14. Explain the problem of distributional shift in model based RL, and write the equation that summarizes this phenomena. [hint: Does it work? No!](https://www.youtube.com/watch?v=LkTmiylbHYk&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=45)<br>\n",
        "\n",
        "> \n",
        "\n",
        "15.    Why is uncertainty estimation important in model based RL? [hint: how uncertainty estimation can help](https://www.youtube.com/watch?v=pSvjDO1B9WY&list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps&index=47)<br>\n",
        "\n",
        "> \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPnPio6d94fy"
      },
      "source": [
        "# Boiler plate\n",
        "\n",
        "Read through at least once.\n",
        "\n",
        "**Will hang until you upload the replay buffer** (every time you restart your runtime)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "id": "NYFcc7tM6LGF"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# @title Imports\n",
        "\n",
        "# !pip install gymnasium[mujoco]\n",
        "# !apt install -y libgl1-mesa-glx libosmesa6 libglfw3 patchelf\n",
        "import gymnasium as gym\n",
        "\n",
        "import torch\n",
        "from torch import nn, zeros\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from collections import deque\n",
        "import random\n",
        "import copy\n",
        "\n",
        "# code should work on either, faster on gpu\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# random seeds for reproducability\n",
        "torch.manual_seed(0)\n",
        "torch.cuda.manual_seed_all(0)\n",
        "random.seed(0)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "cellView": "form",
        "id": "pkZOQqyvnoNB"
      },
      "outputs": [],
      "source": [
        "# @title Define Replay Buffer\n",
        "class ReplayBuffer:\n",
        "    def __init__(self):\n",
        "        self.buffer = deque(maxlen=6000)\n",
        "        self.batch_size = 32\n",
        "\n",
        "    def store(self, state, action, reward, next_state, done):\n",
        "        transitions = list(zip(state, action, reward, next_state, 1 - torch.Tensor(done)))\n",
        "        self.buffer.extend(transitions)\n",
        "\n",
        "    def sample(self):\n",
        "        batch = random.sample(self.buffer, self.batch_size)\n",
        "        # generic replay buffer from hw2, modified to only return (s, a, s')\n",
        "        states, actions, rewards, next_states, not_dones = [torch.stack(e).to(device) for e in zip(*batch)]\n",
        "        return states, actions, next_states\n",
        "\n",
        "replay_buffer = ReplayBuffer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "i4SoSE7i4vmI"
      },
      "outputs": [],
      "source": [
        "# # @title Upload Replay Buffer\n",
        "# from google.colab import files\n",
        "# import pickle\n",
        "\n",
        "# # Prompt the user to upload the file\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# # Load the replay buffer from the uploaded file\n",
        "# file_name = list(uploaded.keys())[0]  # Get the file name\n",
        "# with open(file_name, 'rb') as f:\n",
        "#     replay_buffer = pickle.load(f)\n",
        "\n",
        "# print(f\"Replay buffer loaded with {len(replay_buffer.buffer)} transitions!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Replay buffer loaded with 6000 transitions!\n"
          ]
        }
      ],
      "source": [
        "# @title Upload Replay Buffer\n",
        "import pickle\n",
        "\n",
        "# Load the replay buffer from the uploaded file\n",
        "file_name = \"./replay_buffer_hw3.pkl\"\n",
        "with open(file_name, 'rb') as f:\n",
        "    replay_buffer = pickle.load(f)\n",
        "\n",
        "print(f\"Replay buffer loaded with {len(replay_buffer.buffer)} transitions!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "U73-XPSasnHQ"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n"
          ]
        }
      ],
      "source": [
        "# @title Visualization Code\n",
        "import os\n",
        "from gym.wrappers import RecordVideo\n",
        "from IPython.display import Video, display, clear_output\n",
        "\n",
        "# Force MuJoCo to use EGL for rendering (important for Colab)\n",
        "# os.environ[\"MUJOCO_GL\"] = \"egl\" # TEMPDEAC\n",
        "\n",
        "def visualize(agent):\n",
        "    \"\"\"Visualize agent with a custom camera angle.\"\"\"\n",
        "\n",
        "    # Create environment in rgb_array mode\n",
        "    env = gym.make(\"InvertedPendulum-v5\", render_mode=\"rgb_array\", reset_noise_scale=0.1, frame_skip=5)\n",
        "\n",
        "    # Apply video recording wrapper\n",
        "    env = RecordVideo(env, video_folder=\"./\", episode_trigger=lambda x: True)\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "\n",
        "    # Access the viewer object through mujoco_py\n",
        "    viewer = env.unwrapped.mujoco_renderer.viewer  # Access viewer\n",
        "    viewer.cam.distance = 3.0     # Set camera distance\n",
        "    viewer.cam.azimuth = 90       # Rotate camera around pendulum\n",
        "    viewer.cam.elevation = 0   # Tilt the camera up/down\n",
        "\n",
        "\n",
        "    for t in range(200):\n",
        "        with torch.no_grad():\n",
        "            actions = agent.get_action(torch.Tensor(obs).to(device)[None, :])[:, 0]\n",
        "        obs, _, done, _= env.step(actions.cpu().numpy())\n",
        "        if done:\n",
        "            break\n",
        "    env.close()\n",
        "\n",
        "    # Display the latest video\n",
        "    clear_output(wait=True)\n",
        "    display(Video(\"./rl-video-episode-0.mp4\", embed=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "cellView": "form",
        "id": "Xh2gShdf5Ifl"
      },
      "outputs": [],
      "source": [
        "# @title Evaluation Code\n",
        "\n",
        "def evaluate(agent):\n",
        "\n",
        "    # Create environment in rgb_array mode\n",
        "    env = gym.make(\"InvertedPendulum-v5\", reset_noise_scale=0.1, frame_skip=5)\n",
        "\n",
        "    n = 3\n",
        "    mean_duration = 0\n",
        "    for i in range(n):\n",
        "        obs, _ = env.reset()\n",
        "        done, t = False, 0\n",
        "        while not done and t < 200:\n",
        "            with torch.no_grad():\n",
        "                actions = agent.get_action(torch.Tensor(obs).to(device)[None, :])[:, 0]\n",
        "            obs, _, done, _, _ = env.step(actions.cpu().numpy())\n",
        "            t += 1\n",
        "\n",
        "        mean_duration += t\n",
        "        print(f\"trial {i+1}/{n} lasted {t*.1:.3f} seconds\")\n",
        "\n",
        "    env.close()\n",
        "    print(f\"\\nmean duration: {(mean_duration * .1 / n):.3f} seconds\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek7oKfhX_Umm"
      },
      "source": [
        "#Tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "YNkdtlB5acUS"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
              "          const url = new URL(\"/\", window.location);\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Launch TensorBoard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MV-bVS5d-F6C"
      },
      "source": [
        "# Deterministic Dynamics [20 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTGB_0vkIpmx"
      },
      "source": [
        "#### Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMAcv9gF33ZP"
      },
      "source": [
        "\n",
        "1.   Define the dynamics network $f_\\theta$ and optimizer [5 pts]\n",
        "2.   Define `predict()` and `get_loss()` [5 pts]\n",
        "3.   Finish the training code and run training (code cell below unit test) [5 pts]\n",
        "3.   Conceptual question [5 pts]\n",
        "________________________________________\n",
        "Deterministic Neural Dynamics Modeling\n",
        "\n",
        "Let's start by training a neural network to represent the dynamics of the cartpole system from HW2 using 10 mintues of data collected at 10 Hz from a single robot (6000 transitions). We can assume the data came from a human attemping to control the cartpole with a joystick, but it's suboptimal in terms of performance.\n",
        "\n",
        "We will model the transition function as:\n",
        "\n",
        "$$\n",
        "s_{t+1} = s_t + f_\\theta(s_t, a_t)\n",
        "$$\n",
        "Or equivalently:\n",
        "$$\n",
        "s_{t+1} - s_t = f_\\theta(s_t, a_t)\n",
        "$$\n",
        "\n",
        "Train $f_\\theta(s_t, a_t)$ with Mean Squared Error loss on minibatches from the dataset of transition tuples $\\mathcal{D} = \\{(s, a, s')\\}$\n",
        "\n",
        "_______________________________________\n",
        "\n",
        "Deterministic Neural Dynamics Modeling Loss:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\theta) = \\mathbb{E}[\\{(s_{t+1} - s_t)  - f_\\theta(s_t, a_t)\\}^2]\n",
        "$$\n",
        "\n",
        "\n",
        "Where:\n",
        "- $ \\mathcal{L} $ is the dynamics net loss; a function of network parameters $\\theta$\n",
        "-$s_{t+1}$ is state at timestep $t+1$\n",
        "-$s_t$ is action at timestep $t$\n",
        "-$f_\\theta(s_t, a_t)$ is the dynamics network parametrized by $\\theta$\n",
        "-$\\mathbb{E}$ is the expectation or average over the minibatch\n",
        "\n",
        "(hint: No for loops. Use torch's batched operations for greater training speed.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIjmwKUuIxFl"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "YBr9aIQXNrgA"
      },
      "outputs": [],
      "source": [
        "n_hidden = 100\n",
        "\n",
        "class DeterministicDynamics():\n",
        "    # NOTE: experiment with learning rate and model size, but keep it same for all models\n",
        "    def __init__(self, n_obs, n_actions):\n",
        "        torch.manual_seed(0)\n",
        "        \n",
        "        self.model = nn.Sequential(\n",
        "          nn.Linear(n_obs + n_actions, n_hidden),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(n_hidden, n_hidden),\n",
        "          nn.ReLU(),\n",
        "          nn.Linear(n_hidden, n_obs),\n",
        "          # nn.ReLU(), # turned off, since transition dynamics is delta-encoded\n",
        "        )\n",
        "        # end student code\n",
        "\n",
        "    def predict(self, states, actions):\n",
        "        return self.model(torch.cat([states, actions], dim=-1))\n",
        "        #end student code\n",
        "\n",
        "    def get_loss(self, states, actions, next_states):\n",
        "        delta_states = next_states - states\n",
        "        loss = F.mse_loss(self.predict(states, actions), delta_states)\n",
        "        return loss\n",
        "        # end student code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "ObI1SLjMCDCd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test passed: Deterministic dynamics predict appears correct!\n",
            "Test passed: Deterministic dynamics loss appears correct!\n"
          ]
        }
      ],
      "source": [
        "# @title Unit Tests\n",
        "\n",
        "def determ():\n",
        "    torch.manual_seed(0)\n",
        "    # these dont match an actual rollout..\n",
        "    # print debug values during training loop rather than unit tests\n",
        "    batch_size, n_obs, n_actions = 2, 4, 1\n",
        "    s = torch.rand((batch_size, n_obs))\n",
        "    a = torch.rand((batch_size, n_actions))\n",
        "    s_ = torch.rand((batch_size, n_obs))\n",
        "\n",
        "    dyn = DeterministicDynamics(4, 1)\n",
        "    torch.manual_seed(0)\n",
        "    dyn.model = nn.Linear(5, 4) # you should not use this architecture..\n",
        "\n",
        "    delta = dyn.predict(s, a)\n",
        "    # print(delta)\n",
        "    expected_delta = torch.tensor([[ 0.1906,  0.5041, -0.3875,  0.3737],\n",
        "        [-0.2708,  0.6156, -0.7808,  0.1884]])\n",
        "    assert torch.allclose(delta, expected_delta, atol=1e-4), \\\n",
        "    \"Deterministic dynamics predict does not match expected value.\"\n",
        "    print(\"Test passed: Deterministic dynamics predict appears correct!\")\n",
        "\n",
        "\n",
        "    loss = dyn.get_loss(s, a, s_)\n",
        "    # print(loss)\n",
        "    assert abs(loss.item() - (0.3435)) < 1e-4, \\\n",
        "    \"Deterministic dynamics loss does not match expected value.\"\n",
        "    print(\"Test passed: Deterministic dynamics loss appears correct!\")\n",
        "\n",
        "determ()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "sZTnCiJV-mS9"
      },
      "outputs": [],
      "source": [
        "# writer = SummaryWriter(log_dir=f'runs/deterministic')\n",
        "# # NOTE: if you need extra hints here check out the analagous code in HW1 and HW2\n",
        "\n",
        "# # params\n",
        "# env = gym.make(\"InvertedPendulum-v5\")\n",
        "# lr = 1e-4\n",
        "\n",
        "# n_obs = env.observation_space.shape[0]\n",
        "# n_actions = env.action_space.shape[0]\n",
        "# deterministic_dynamics = DeterministicDynamics(n_obs, n_actions)\n",
        "# deterministic_dynamics.model.train()\n",
        "# optimizer = torch.optim.AdamW(deterministic_dynamics.model.parameters(), lr=lr, weight_decay=1e-2)\n",
        "\n",
        "# for i in range(30_000): # train over 30,000 minibatch samples\n",
        "#     states, actions, next_states = replay_buffer.sample()\n",
        "    \n",
        "#     # pred = deterministic_dynamics.predict(states, actions)\n",
        "#     optimizer.zero_grad()  # reset gradient\n",
        "#     loss = deterministic_dynamics.get_loss(states, actions, next_states)\n",
        "#     loss.backward()\n",
        "\n",
        "#     torch.nn.utils.clip_grad_norm_(deterministic_dynamics.model.parameters(), 1.0)  # optional\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # end student code\n",
        "#     writer.add_scalar(\"stats/mse_loss\", loss.item(), i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_3kToTl8AOw"
      },
      "source": [
        "#### Conceptual Question\n",
        "\n",
        "1. In the context of RL for physical control, why learn a dynamics model rather than (1) training directly on a hardware system or (2) deriving a simulator for our system by hand?<br>\n",
        "\n",
        "> (1) Direct training on hardware system is likely to be prohibitively expensive and dangerous (i.e., you *don't* want to roll out random actions into a physical robot). \n",
        "\n",
        "> (2) Not all physical phenomena can be easily implemented in a physics simulator; for example — fluid and soft-body mechanics are extremely hard to derive/integrate, even numerically. Model-based RL allows you to insert some of the knowledge you know (e.g., physical equations derived by great mathematicians and physicists) while retaining the data-driven aspect that is suited for handling real-world chaos and complexity. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQj9reBb_tV7"
      },
      "source": [
        "# Cross Entropy Method [20 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZQDZHPrPs9E"
      },
      "source": [
        "#### Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O29F34w3Ry-0"
      },
      "source": [
        "\n",
        "1.   Finish implementing CEM `get_action()` and run deterministic CEM [15 pts]\n",
        "2.   Conceptual question [5 pts]\n",
        "_______________________________\n",
        "\n",
        "Background\n",
        "\n",
        "Now that we have a model, it's time to plan. We will use the Cross Entropy Method - possibly the simplest online planning algorithm. It's a sampling based evolutionary algorithm that iteratively reduces the cross entropy between our distribution over actions and the optimal disribution over actions at each time step. We start with a random distribution over actions, sample from it, simulate the outcomes and calculate their returns, grab a subset of the best performing actions, and use those to refit our random distribution over actions. Repeat until convergence (in theory) or for a fixed number of iterations (in practice). Replan at every timestep. For further explanation check out the hints in the warm up questions.\n",
        "\n",
        "We are doing open loop planning by solving this constrained optimization:\n",
        "\n",
        "$$\n",
        "a_1^*, ..., a_T^* = \\arg\\max_{a_1, ..., a_T} \\sum_{t=1}^{T} r_t  \\\\\n",
        "\\quad \\quad \\text{subject to} \\quad s_{t+1} = s_t + f_\\theta(s_t, a_t)\n",
        "$$\n",
        "\n",
        "_______________________________\n",
        "Pseudocode for CEM\n",
        "\n",
        "\n",
        "A. Initialize distribution\n",
        "- Create mean = 0, std_dev = 1 tensors for T timesteps and n_action dimensions  (done for you)\n",
        "\n",
        "B. Loop over CEM iterations:  \n",
        "\n",
        "- Randomly sample n_samples parallel action sequences (done for you)\n",
        "\n",
        "- Loop over timesteps T\n",
        "     - Simulate the action sequences in parallel using $f_\\theta$   \n",
        "     - Use `torch.no_grad()` to disable gradient tracking\n",
        "     - Accumulate undiscounted returns at each timestep\n",
        "\n",
        "- Select elite actions:  \n",
        "     - Choose the n_elite action sequences with the highest returns\n",
        "\n",
        "- Refit distribution:  \n",
        "     - Refit mean and std_dev to the n_elite actions\n",
        "     - Clamp the minimum std_dev to .5 to prevent collapse and ensure exploration\n",
        "\n",
        "C. MPC return\n",
        "- Return the mean action for the first timestep only\n",
        "- It should be a tensor of size `torch.Size([1, n_actions])`, since our batching dimension is 1\n",
        "\n",
        "(hint: understand dimensions of all tensors)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "         \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVErJJ_cRzbu"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "alm4mgyipEhX"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import Normal\n",
        "\n",
        "class CEM:\n",
        "    def __init__(self, dynamics):\n",
        "        self.dynamics: DeterministicDynamics = dynamics\n",
        "        self.T = 10  # planning time horizon\n",
        "        self.n_actions = 1\n",
        "        self.cem_iter = 20\n",
        "        self.n_samples = 1000\n",
        "        self.n_elite = 200\n",
        "\n",
        "    def compute_rewards(self, state):\n",
        "        reward_t = -state[..., 0].square() / 5.  # incremental position penalty\n",
        "        reward_t -= state[..., 1].square()  # incremental angle penalty\n",
        "        # angle and position limits\n",
        "        soft_done = torch.logical_or(state[..., 1].abs() > 0.2, state[..., 0].abs() > 1.)\n",
        "        reward_t +=  1 - 2 * soft_done.float()\n",
        "        return reward_t\n",
        "\n",
        "    def get_action(self, initial_states):\n",
        "        mean = torch.zeros((self.T, self.n_actions))\n",
        "        std_dev = torch.ones((self.T, self.n_actions))\n",
        "\n",
        "        for i in range(self.cem_iter):\n",
        "            # initial random rollout (before CEM)\n",
        "            states = initial_states.repeat(self.n_samples, 1)\n",
        "            actions = Normal(mean, std_dev).sample((self.n_samples,)).clamp(-3, 3).to(device)\n",
        "            returns = torch.zeros((self.n_samples,))\n",
        "\n",
        "            # roll out actions in batch (for T steps)\n",
        "            for j in range(self.T):  # using for loop since chronological dependency and low loop repeat n\n",
        "                with torch.no_grad():\n",
        "                    next_states_pred = self.dynamics.predict(states, actions[:,j,...])  # sa: state & action\n",
        "                states = next_states_pred  # alias (for loop update)\n",
        "                returns += self.compute_rewards(states)\n",
        "\n",
        "            # choose elites & re-fit\n",
        "            returns_sorted, idx_sorted = returns.sort(dim=0, descending=True)\n",
        "            elite_actions = actions[idx_sorted[:self.n_elite], ...]\n",
        "            elite_std, elite_mean = torch.std_mean(elite_actions, dim=0)\n",
        "            mean, std_dev = elite_mean, elite_std  # alias (for loop update)\n",
        "            std_dev = std_dev.clamp_min(0.5)  # min_clamp std to ensure exploration\n",
        "\n",
        "        # return actions[idx_sorted[0], 0, ...].unsqueeze(-1)\n",
        "        return mean[0].unsqueeze(-1)\n",
        "        # end student code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "id": "jI2wdtTGAUn3"
      },
      "outputs": [
        {
          "ename": "AssertionError",
          "evalue": "Action value appears wrong",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[12], line 29\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(a\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m  (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.4642404317855835\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-4\u001b[39m, \\\n\u001b[1;32m     25\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction value appears wrong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest passed: CEM Action appears correct!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 29\u001b[0m \u001b[43mcem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[12], line 21\u001b[0m, in \u001b[0;36mcem\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# print(a.item())\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(a\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m  (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.4559649229049683\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-4\u001b[39m, \\\n\u001b[1;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction value appears wrong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;66;03m#todo fix this...\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(a\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m-\u001b[39m  (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1.4642404317855835\u001b[39m)) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1e-4\u001b[39m, \\\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAction value appears wrong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
            "\u001b[0;31mAssertionError\u001b[0m: Action value appears wrong"
          ]
        }
      ],
      "source": [
        "# @title Unit Tests\n",
        "\n",
        "def cem():\n",
        "    torch.manual_seed(0)\n",
        "    # these dont match an actual rollout..\n",
        "    # print debug values during training loop rather than unit tests\n",
        "    batch_size, n_obs = 1, 4\n",
        "    s = 2*torch.rand((batch_size, n_obs)).to(device)-3\n",
        "\n",
        "    dyn = DeterministicDynamics(4, 1)\n",
        "    torch.manual_seed(0)\n",
        "    dyn.model = nn.Linear(5, 4).to(device) # you should not use this architecture..\n",
        "    cem = CEM(dyn)\n",
        "    a = cem.get_action(s)\n",
        "\n",
        "    assert a.shape == torch.Size([1, 1]), \\\n",
        "    \"Action size appears wrong\"\n",
        "\n",
        "    # print(a.item())\n",
        "    if device == 'cpu':\n",
        "        assert abs(a.item() -  (-1.4559649229049683)) < 1e-4, \\\n",
        "        \"Action value appears wrong\"\n",
        "    else: #todo fix this...\n",
        "        assert abs(a.item() -  (-1.4642404317855835)) < 1e-4, \\\n",
        "        \"Action value appears wrong\"\n",
        "\n",
        "    print(\"Test passed: CEM Action appears correct!\")\n",
        "\n",
        "cem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "XAps_QiN-XCO"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'deterministic_dynamics' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[73], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m cem \u001b[38;5;241m=\u001b[39m CEM(\u001b[43mdeterministic_dynamics\u001b[49m)\n\u001b[1;32m      2\u001b[0m visualize(cem)\n\u001b[1;32m      3\u001b[0m evaluate(cem)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'deterministic_dynamics' is not defined"
          ]
        }
      ],
      "source": [
        "cem = CEM(deterministic_dynamics)\n",
        "visualize(cem)\n",
        "evaluate(cem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnva8EL_KViw"
      },
      "source": [
        "#### Conceptual Questions\n",
        "1. What're the pros and cons of real time planning (like this CEM method) vs policy learning (like REINFORCE, DQN, PPO, etc)?<br>\n",
        "\\\n",
        "Type answer here..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRf3Kl0sERdX"
      },
      "source": [
        "# Stochastic Dynamics [15 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTXy-sDbPnu7"
      },
      "source": [
        "#### Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eStbMg4P0jU"
      },
      "source": [
        "1.   Define the stochastic dynamics network $f_\\theta$ and optimizer [5 pts]\n",
        "2.   Define `predict()` and `get_loss()` [5 pts]\n",
        "3.   Finish the training code, run training, run stochastic CEM [5 pts]\n",
        "3.   Conceptual question [5 pts]\n",
        "___________________________________\n",
        "Background\n",
        "\n",
        "We know trajectory optimization over learned models introduces challeneges due to distribution shift and error accumulation. We also know this problem is worse when modeling with neural nets. Let's try modeling our dynamics as a stochastic system and planning in expectation over the dynamics. We will theoretically model the state transition function as:\n",
        "\n",
        "$$\n",
        "\\mu_t, \\sigma_t = f_\\theta(s_t, a_t)\\\\\n",
        "s_{t+1} - s_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t)\n",
        "$$\n",
        "\n",
        "\n",
        "Where mean $\\mu_t$ and standard deviation $\\sigma_t$ form normal distribution $\\mathcal{N}$ from which transitions are sampled. In practice we have to use these slightly less elegant equations to keep $\\sigma_t$ positive and bounded:\n",
        "\n",
        "$$\n",
        "\\mu_t, \\log \\sigma_t = f_\\theta(s_t, a_t)\\\\\n",
        "\\sigma_t = \\text{clamp} (e^{\\log \\sigma_t}, 10^{-8}, 10)  \\\\\n",
        "s_{t+1} - s_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t)\n",
        "$$\n",
        "\n",
        "Where:  \n",
        "- $ \\mu_t $ is the mean of the predicted state difference\n",
        "- $ \\log \\sigma_t $ is the log of the standard deviation, modeling the uncertainty in the transition\n",
        "- $ e^{\\log \\sigma_t}$ ensures positivity\n",
        "- $\\text{clamp}()$ ensures numerical stability\n",
        "-  $\\sim$ denotes random sampling\n",
        "- $\\mathcal{N}$ denotes Normal aka Guassian Distribution\n",
        "\n",
        "___________________________________\n",
        "\n",
        "Stochastic Neural Dynamics Loss  \n",
        "\n",
        "Instead of minimizing a simple squared error loss, we now minimize the **Gaussian Negative Log-Likelihood (NLL) loss**, which accounts for both the predicted mean and uncertainty:  \n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\theta) = \\mathbb{E} \\left[ \\frac{((s_{t+1} - s_t) - \\mu_t)^2}{2\\sigma_t^2} + \\log \\sigma_t \\right]\n",
        "$$\n",
        "\n",
        "where:  \n",
        "- $ \\mathcal{L}(\\theta) $ is the stochastic dynamics loss, a function of network parameters $ \\theta $\n",
        "- $ s_{t+1} $ is the state at timestep $ t+1 $\n",
        "- $ s_t $ is the state at timestep $ t $\n",
        "- $ \\mu_t $ is the mean prediction of the state transition\n",
        "- $ \\sigma_t $ is the predicted standard deviation\n",
        "- $ \\mathbb{E} $ denotes the expectation (average over the minibatch)\n",
        "\n",
        "(hint: don't actually implement that equation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n00uTRbPp5e"
      },
      "source": [
        "#### Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajTXsJn_VII9"
      },
      "outputs": [],
      "source": [
        "from torch.distributions import Normal\n",
        "\n",
        "class StochasticDynamics():\n",
        "    def __init__(self, n_obs, n_actions):\n",
        "        torch.manual_seed(0)\n",
        "        # Student code here\n",
        "        self.model = None\n",
        "\n",
        "        # end student code\n",
        "\n",
        "    def predict(self, states, actions):\n",
        "        # Student code here\n",
        "\n",
        "\n",
        "        return None\n",
        "        # end student code\n",
        "\n",
        "    def get_loss(self, states, actions, next_states):\n",
        "        # Student code here\n",
        "\n",
        "\n",
        "        return None\n",
        "        # end student code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "cfnTFoBDgKkF"
      },
      "outputs": [],
      "source": [
        "# @title Unit Tests\n",
        "\n",
        "def stoch():\n",
        "    torch.manual_seed(0)\n",
        "    # these dont match an actual rollout..\n",
        "    # print debug values during training loop rather than unit tests\n",
        "    batch_size, n_obs, n_actions = 2, 4, 1\n",
        "    s = torch.rand((batch_size, n_obs))\n",
        "    a = torch.rand((batch_size, n_actions))\n",
        "    s_ = torch.rand((batch_size, n_obs))\n",
        "\n",
        "    dyn = StochasticDynamics(4, 1)\n",
        "    torch.manual_seed(0)\n",
        "    dyn.model = nn.Linear(5, 8) # you should not use this architecture..\n",
        "\n",
        "    delta = dyn.predict(s, a)\n",
        "    # print(delta)\n",
        "    expected_delta = torch.tensor([[ 0.2525,  1.1405, -1.9571, -1.1799],\n",
        "        [-0.4345, -0.4267, -0.1200, -2.6686]])\n",
        "    assert torch.allclose(delta, expected_delta, atol=1e-4), \\\n",
        "    \"Stochastic dynamics predict does not match expected value.\"\n",
        "    print(\"Test passed: Stochastic dynamics predict appears correct!\")\n",
        "\n",
        "\n",
        "    loss = dyn.get_loss(s, a, s_)\n",
        "    # print(loss)\n",
        "    assert abs(loss.item() - (0.1352)) < 1e-4, \\\n",
        "    \"Stochastic dynamics loss does not match expected value.\"\n",
        "    print(\"Test passed: Stochastic dynamics loss appears correct!\")\n",
        "\n",
        "stoch()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcGTlzR7QTp1"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter(log_dir=f'runs/stochastic')\n",
        "# student code here\n",
        "stochastic_dynamics = None\n",
        "\n",
        "\n",
        "for i in range(30_000):\n",
        "\n",
        "\n",
        "    # end student code\n",
        "    writer.add_scalar(\"stats/nll_loss\", loss.item(), i)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJulXk-ItcpL"
      },
      "source": [
        "You don't have to change any CEM code, but if you implemented the sampling based `predict()` function, then you're now solving the planning problem in expectation over stochastic state transitions:\n",
        "\n",
        "$$\n",
        "a_1^*, ..., a_T^* = \\arg\\max_{a_1, ..., a_T} \\mathbb{E}_{s_{t+1} \\sim p(s_{t+1} | s_t, a_t)} \\left[ \\sum_{t=1}^{T} r_t \\right]\n",
        " \\\\\n",
        "\\quad \\quad \\text{subject to} \\quad s_{t+1} - s_t \\sim \\mathcal{N}(\\mu_t, \\sigma_t)\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuZ71YPdV4Vx"
      },
      "outputs": [],
      "source": [
        "cem = CEM(stochastic_dynamics)\n",
        "visualize(cem)\n",
        "evaluate(cem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i080ExTee7h7"
      },
      "source": [
        "#### Conceptual Questions\n",
        "1. What type of uncertanity does our stochastic dynamics model capture? Is this the right type of uncertainty to use for modeling our system? Why or why not.<br>\n",
        "\\\n",
        "Type answer here...\n",
        "\n",
        "2. Did stochastic modeling help or hurt your mean duration relative to deterministic modeling on this problem? Hypothesize why. (Either outcome is fine - your answer just has to make sense.)<br>\n",
        "\\\n",
        "Type answer here...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29GdWgzyEHV-"
      },
      "source": [
        "# Ensembled Dynamics [15 pts]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVCQ59AKUOmJ"
      },
      "source": [
        "#### Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8KZJRFNUcq8"
      },
      "source": [
        "1.   Define a list of dynamics networks $f_{\\theta_j}$, a single optimizer, batch `predict()`, and `get_loss(..., j)`, finish and run training code [5 pts]\n",
        "2.   Update CEM for ensembled dynamics and run it [5 pts]\n",
        "3.   Conceptual questions [5 pts]\n",
        "________________________________________\n",
        "Background\n",
        "\n",
        "Modelling our system as stochastic doesn't capture all types of uncertainty. Let's try a different technique. Train 5 deterministic dynamics models, and plan in expectation over all of them. We will model the transition functions as:\n",
        "\n",
        "$$\n",
        "s_{t+1} - s_t = f_{\\theta_j}(s_t, a_t), \\quad \\forall j \\in \\{1, 2, 3, 4, 5\\}\n",
        "$$\n",
        "\n",
        "Where each $f_{\\theta_j}$ is independently initialized and trained on independent minibatches from $\\mathcal{D} = \\{(s, a, s')\\}$.\n",
        "\n",
        "___________________________________\n",
        "\n",
        "Ensembled Dynamics Modeling Loss:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\theta) = \\sum_{j=1}^{N} \\mathbb{E}[\\{(s_{t+1} - s_t)  - f_{\\theta_j}(s_t, a_t)\\}^2]\n",
        "$$\n",
        "\n",
        "Where $ (s, a, s') $ are sampled independently from $ \\mathcal{D}$ for each network $f_{\\theta_j}$.\n",
        "\n",
        "\n",
        "And:\n",
        "- $ \\mathcal{L} $ is the total ensemble loss; a function of all $j$ network parameters $\\theta_j$\n",
        "- $N$ is the number of networks in the ensemble\n",
        "-$s_{t+1}$ is state at timestep $t+1$\n",
        "-$s_t$ is action at timestep $t$\n",
        "-$f_{\\theta_j}(s_t, a_t)$ is the $j^{th}$ dynamics network parametrized by $\\theta_j$\n",
        "-$\\mathbb{E}$ is the expectation or average over the minibatch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23IJf81uUOSY"
      },
      "source": [
        "#### Code\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uigT0cIFrUDP"
      },
      "outputs": [],
      "source": [
        "class EnsembleDynamics():\n",
        "    def __init__(self, n_obs, n_actions):\n",
        "        torch.manual_seed(0)\n",
        "        self.N = 5\n",
        "        # Student code here\n",
        "        self.models = None\n",
        "\n",
        "        # end student code\n",
        "\n",
        "    # first dimension of states and return should be N\n",
        "    def predict(self, states, actions):\n",
        "        # student code here\n",
        "        return None\n",
        "        # end student code\n",
        "\n",
        "\n",
        "    def get_loss(self, states, actions, next_states, j):\n",
        "        # student code here\n",
        "        return None # loss of jth model\n",
        "        # end student code\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6E5fQdSQgUbY"
      },
      "outputs": [],
      "source": [
        "# @title Unit Tests (Non Exhaustive)\n",
        "\n",
        "def ensemb():\n",
        "    torch.manual_seed(0)\n",
        "    # these dont match an actual rollout..\n",
        "    # print debug values during training loop rather than unit tests\n",
        "    batch_size, n_obs, n_actions, N = 2, 4, 1, 5\n",
        "    s = torch.rand((N, batch_size, n_obs))\n",
        "    a = torch.rand((batch_size, n_actions))\n",
        "    s_ = torch.rand((N, batch_size, n_obs))\n",
        "\n",
        "    dyn = EnsembleDynamics(4,1)\n",
        "    torch.manual_seed(0)\n",
        "    dyn.models = [nn.Linear(5, 4)]*5 # you should not do this ..\n",
        "\n",
        "    delta = dyn.predict(s, a)\n",
        "    # print(delta)\n",
        "    expected_delta = torch.tensor([[[ 0.1784,  0.5125, -0.4006,  0.3599],\n",
        "         [-0.2039,  0.5696, -0.7091,  0.2641]],\n",
        "\n",
        "        [[-0.0387,  0.5905, -0.5743,  0.3233],\n",
        "         [-0.1179,  0.4850, -0.4340,  0.2391]],\n",
        "\n",
        "        [[ 0.1092,  0.5561, -0.5061,  0.3428],\n",
        "         [-0.0961,  0.5799, -0.7381,  0.3018]],\n",
        "\n",
        "        [[-0.1596,  0.8154, -0.7121,  0.5816],\n",
        "         [-0.2096,  0.4903, -0.6012,  0.1556]],\n",
        "\n",
        "        [[ 0.0700,  0.5045, -0.3103,  0.3136],\n",
        "         [-0.1676,  0.6439, -0.7756,  0.4240]]])\n",
        "    assert torch.allclose(delta, expected_delta, atol=1e-4), \\\n",
        "    \"Ensemble dynamics predict does not match expected value.\"\n",
        "    print(\"Test passed: Ensemble dynamics predict appears correct!\")\n",
        "\n",
        "\n",
        "    loss = dyn.get_loss(s[0], a, s_[0], 0)\n",
        "    # print(loss)\n",
        "    assert abs(loss.item() - (0.4017)) < 1e-4, \\\n",
        "    \"Ensemble dynamics loss does not match expected value.\"\n",
        "    print(\"Test passed: Ensemble dynamics loss appears correct!\")\n",
        "\n",
        "ensemb()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YK5qlmm5rcyv"
      },
      "outputs": [],
      "source": [
        "writer = SummaryWriter(log_dir=f'runs/ensembled')\n",
        "\n",
        "# student code here\n",
        "ensemble_dynamics = None\n",
        "\n",
        "for i in range(30_000):\n",
        "\n",
        "    # end student code\n",
        "    writer.add_scalar(\"stats/mse_loss\", loss.item() / ensemble_dynamics.N, i)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVZr5Lsd8uat"
      },
      "source": [
        "Update your CEM implementation below so it solves the following constrained optimization in expectation over the $N$ models in your ensemble:\n",
        "\n",
        "\n",
        "\\begin{aligned}\n",
        "a_1^*, ..., a_T^* &= \\arg\\max_{a_1, ..., a_T} \\frac{1}{N} \\sum_{j=1}^{N} \\sum_{t=1}^{T} r_t^{(j)} \\\\\n",
        "\\\\\n",
        "\\text{subject to} \\quad s_{t+1}^{(j)} &= s_t^{(j)} + f_{\\theta_j}(s_t^{(j)}, a_t), \\quad \\forall j \\in \\{1, ..., N\\} \\\\\n",
        "\\\\\n",
        "\\text{given} \\quad s_0^{(j)} &= s_0, \\quad \\forall j \\in \\{1, ..., N\\}\n",
        "\\end{aligned}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qFNgOgbLxJ8q"
      },
      "outputs": [],
      "source": [
        "# copy paste your CEM code from above, and update it for ensembles\n",
        "# student code here\n",
        "\n",
        "\n",
        "# end student code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "dzdofMVigSH6"
      },
      "outputs": [],
      "source": [
        "# @title Unit Tests (Non Exhaustive)\n",
        "\n",
        "def ensemble_cem():\n",
        "    torch.manual_seed(0)\n",
        "    # these dont match an actual rollout..\n",
        "    # print debug values during training loop rather than unit tests\n",
        "    batch_size, n_obs = 1, 4\n",
        "    s = 2*torch.rand((batch_size, n_obs)).to(device)-3\n",
        "\n",
        "    dyn = EnsembleDynamics(4, 1)\n",
        "    torch.manual_seed(0)\n",
        "    dyn.models = [nn.Linear(5, 4).to(device)]*5 # you should not do this ..\n",
        "    cem = CEM(dyn)\n",
        "    a = cem.get_action(s)\n",
        "\n",
        "    assert a.shape == torch.Size([1, 1]), \\\n",
        "    \"Action size appears wrong\"\n",
        "\n",
        "    # print(a.item())\n",
        "    if device == 'cpu':\n",
        "        assert abs(a.item() -  (-1.4559649229049683)) < 1e-4, \\\n",
        "        \"Action value appears wrong\"\n",
        "    else: #todo fix this...\n",
        "        assert abs(a.item() -  (-1.4642404317855835)) < 1e-4, \\\n",
        "        \"Action value appears wrong\"\n",
        "    print(\"Test passed: CEM Action appears correct!\")\n",
        "\n",
        "ensemble_cem()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jBEquIRx-lS"
      },
      "outputs": [],
      "source": [
        "cem = CEM(ensemble_dynamics)\n",
        "visualize(cem)\n",
        "evaluate(cem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWKbjYR9fqrO"
      },
      "source": [
        "#### Conceptual Question\n",
        "\n",
        "1. What type of uncertanity does our ensembled dynamics model capture? Is this the right type of uncertainty for our problem? Why or why not.<br>\n",
        "\\\n",
        "Type answer here...\n",
        "\n",
        "2. Did ensembled modeling help or hurt your mean duration relative to deterministic modeling on this problem? Hypothesize why. (Either outcome is fine - your answer just has to make sense.)<br>\n",
        "\\\n",
        "Type answer here..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "8PHhuXXvnxb8",
        "bPnPio6d94fy",
        "Ek7oKfhX_Umm",
        "MV-bVS5d-F6C",
        "BTGB_0vkIpmx",
        "aIjmwKUuIxFl",
        "tQj9reBb_tV7",
        "AZQDZHPrPs9E",
        "jVErJJ_cRzbu",
        "yRf3Kl0sERdX",
        "JTXy-sDbPnu7",
        "3n00uTRbPp5e",
        "29GdWgzyEHV-",
        "kVCQ59AKUOmJ",
        "23IJf81uUOSY"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
